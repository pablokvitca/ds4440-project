{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "final_adv_fann.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "19J0SKfqfKKp"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDzSUXGP92jL"
      },
      "source": [
        "# Fake News Detection with Adversarial Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_t1IOSl92ZU"
      },
      "source": [
        "## Set-up Stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otTpgvbYrGyi",
        "outputId": "e671ca2b-d6f7-4f5e-f75c-efb38b683ee0"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOwt1xySgMe7"
      },
      "source": [
        "# Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable, Function\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from collections import OrderedDict\n",
        "from time import time\n",
        "from os import path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRlh9fWlMJPL"
      },
      "source": [
        "# import pdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEC87BzZi30h",
        "outputId": "fc9d40ab-c7f2-4adf-9e33-b2ec75fd7402"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IURvV-egV4e",
        "outputId": "e5c9f6f4-5627-48c8-f8fd-213d0a819f23"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Wed Dec 16 20:32:09 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    24W / 300W |     10MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 27.4 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvARRPIB962s"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH_SlA0ggKG1"
      },
      "source": [
        "source_folder = '/content/drive/My Drive/Projects/Academic/NN/data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXA1V_QjrENH"
      },
      "source": [
        "destination_folder = '/content/drive/My Drive/Projects/Academic/NN/final_output/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx4ThDEth-6K"
      },
      "source": [
        "unbalanced_train_data_path = source_folder + \"train_unbalanced.csv\"\n",
        "unbalanced_test_data_path = source_folder + \"test_unbalanced.csv\"\n",
        "unbalanced_validation_data_path = source_folder + \"validation_unbalanced.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo5EhrXpiL5J",
        "outputId": "1484b214-af45-4a77-a547-60508f17b53f"
      },
      "source": [
        "def load_from_csv(path):\n",
        "    print(\"Loading:\", path) \n",
        "    return pd.read_csv(path, encoding=\"utf-8\", quotechar='\"', engine=\"c\", error_bad_lines=False, warn_bad_lines=True)\n",
        "\n",
        "unbal_data_train = load_from_csv(unbalanced_train_data_path)\n",
        "unbal_data_test = load_from_csv(unbalanced_test_data_path)\n",
        "unbal_data_val = load_from_csv(unbalanced_validation_data_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading: /content/drive/My Drive/Projects/Academic/NN/data/train_unbalanced.csv\n",
            "Loading: /content/drive/My Drive/Projects/Academic/NN/data/test_unbalanced.csv\n",
            "Loading: /content/drive/My Drive/Projects/Academic/NN/data/validation_unbalanced.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpNPofG4zmVD"
      },
      "source": [
        "class FNDataset(Dataset):\n",
        "    def __init__(self, news, targets, keywords, indexes, tokenizer, max_tokens):\n",
        "        self._news = news\n",
        "        self.targets = targets\n",
        "        self.keywords = keywords\n",
        "        self.indexes = indexes\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_tokens = max_tokens\n",
        "\n",
        "        self.keyword_2_int = {}\n",
        "        self.int_2_keyword = {}\n",
        "        for i, keyword in enumerate(set(keywords.tolist())):\n",
        "            self.keyword_2_int[keyword] = i\n",
        "            self.int_2_keyword[i] = keyword\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self._news)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        news_item = self._news[item]\n",
        "        target = self.targets[item]\n",
        "        keyword = self.keyword_2_int[self.keywords[item]]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            news_item,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_tokens,\n",
        "            truncation=True,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        item_index = self.indexes[item]\n",
        "        \n",
        "        # news_item, input_ids, attention_mask, target, keyword, item index\n",
        "        return  news_item, \\\n",
        "                encoding['input_ids'].flatten(), \\\n",
        "                encoding['attention_mask'].flatten(), \\\n",
        "                torch.tensor(target, dtype=torch.long), \\\n",
        "                torch.tensor(keyword, dtype=torch.long), \\\n",
        "                item_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZRf2o5gzpuP"
      },
      "source": [
        "def get_data_loader(df, tokenizer, max_tokens, batch_size, shuffle=True):\n",
        "    return DataLoader(\n",
        "        FNDataset(\n",
        "            df.title_content.to_numpy(),\n",
        "            df.fake.to_numpy(),\n",
        "            df.keyword.to_numpy(),\n",
        "            df.index.to_numpy(),\n",
        "            tokenizer,\n",
        "            max_tokens\n",
        "        ),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=4\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0E-qzheMqEW"
      },
      "source": [
        "ADV_CLASSES = len(\n",
        "    set(\n",
        "        list(unbal_data_train.keyword.unique()) + \\\n",
        "        list(unbal_data_test.keyword.unique()) + \\\n",
        "        list(unbal_data_val.keyword.unique())\n",
        "        )\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40hXRpOp-C-u"
      },
      "source": [
        "MAX_TOKENS = 512\n",
        "BATCH_SIZE = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz0iLPlDorqw"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgR2fswfZ0zV"
      },
      "source": [
        "unbal_train_data_loader = get_data_loader(unbal_data_train.sample(12_000, random_state=1001), tokenizer, MAX_TOKENS, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nex4Q0sXAepx"
      },
      "source": [
        "unbal_test_data_loader = get_data_loader(unbal_data_test, tokenizer, MAX_TOKENS, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVcTaeeRAeal"
      },
      "source": [
        "unbal_val_data_loader = get_data_loader(unbal_data_val, tokenizer, MAX_TOKENS, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wdi3IhyfK4u"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAf8Qa_1osd-"
      },
      "source": [
        "# LAMBDA_ARG = 1\n",
        "class ReverseLayerF(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return (grad_output * - 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSce6Gy0p_G-"
      },
      "source": [
        "# Define Network\n",
        "\n",
        "class FANN(nn.Module):\n",
        "\n",
        "    def __init__(self, \n",
        "                hidden_dim=1024,\n",
        "                pre_trained_model_name='bert-base-cased',\n",
        "                bert_max_tokens=512,\n",
        "                dropout=0.2,\n",
        "                fnews_classes=2,\n",
        "                fnews_col=\"fake\",\n",
        "                use_adv=True,\n",
        "                use_pooled=True,\n",
        "                adv_classes=-1):\n",
        "        super(FANN, self).__init__()\n",
        "\n",
        "        assert not use_adv or adv_classes > 1, \\\n",
        "            \"Adversarial network requires at least 2 classes for adversary network\"\n",
        "        assert fnews_classes >= 2, \"Fake news classes must be at least 2\"\n",
        "\n",
        "        self.hidden_dim             = hidden_dim\n",
        "        self.pre_trained_model_name = pre_trained_model_name\n",
        "        self.bert_max_tokens        = bert_max_tokens\n",
        "        self.dropout                = dropout\n",
        "        self.fnews_classes          = fnews_classes\n",
        "        self.fnews_col              = fnews_col\n",
        "        self.use_adv                = use_adv\n",
        "        self.use_pooled             = use_pooled\n",
        "        self.adv_classes            = adv_classes\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(self.pre_trained_model_name)\n",
        "        self.bert_dims = self.bert.config.hidden_size\n",
        "\n",
        "        self.base_in = self.bert_dims if self.use_pooled else self.bert_max_tokens * self.bert_dims\n",
        "        self.base_out = self.bert_dims\n",
        "\n",
        "        self.base_seq = nn.Sequential(OrderedDict([\n",
        "            ('base_linear',  nn.Linear(self.base_in, self.base_out)),\n",
        "            ('base_act',     nn.LeakyReLU()),\n",
        "        ]))\n",
        "\n",
        "        # Fake News Classifier\n",
        "        self.fnews_classifier = nn.Sequential(OrderedDict([\n",
        "            ('fn_linear',    nn.Linear(self.bert_dims, self.fnews_classes)),\n",
        "            ('fn_softmax',   nn.Softmax(dim=1))\n",
        "        ]))\n",
        "\n",
        "        # Adverssarial Classifier\n",
        "        if self.use_adv:\n",
        "            self.adv_classifier = nn.Sequential(OrderedDict([\n",
        "                ('adv_linear',  nn.Linear(self.bert_dims, self.adv_classes)),\n",
        "                ('adv_softmax', nn.Softmax(dim=1))\n",
        "            ]))\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        mean, std = 0.0, 0.001\n",
        "        def normal_init(m):\n",
        "            if isinstance(m, nn.Linear):\n",
        "                m.weight.data.normal_(mean, std)\n",
        "                if m.bias.data is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "        def init_w(m):\n",
        "            for block in self._modules:\n",
        "                try:\n",
        "                    for m in self._modules[block]:\n",
        "                        normal_init(m)\n",
        "                except:\n",
        "                    normal_init(block)\n",
        "\n",
        "        self.bert.init_weights()\n",
        "        self.base_seq.apply(init_w)\n",
        "        self.fnews_classifier.apply(init_w)\n",
        "        if self.use_adv:\n",
        "            self.adv_classifier.apply(init_w)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_output = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        bert_embedded, bert_pooled = bert_output[0], bert_output[1]\n",
        "        base_output = None\n",
        "        if self.use_pooled:\n",
        "            base_output = self.base_seq(bert_pooled)\n",
        "        else:\n",
        "            bo_shape = bert_embedded.shape # view(batch size, token_length * bert_dims)\n",
        "            embedded_output = bert_embedded.view(bo_shape[0], bo_shape[1] * bo_shape[2])\n",
        "            base_output = self.base_seq(embedded_output)\n",
        "\n",
        "        predicted_fnews_class = self.fnews_classifier(base_output)\n",
        "\n",
        "        predicted_adv_class = None\n",
        "        if self.use_adv:\n",
        "            predicted_adv_class = self.adv_classifier(ReverseLayerF.apply(base_output))\n",
        "        \n",
        "        return predicted_fnews_class, predicted_adv_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nmx0DWpWlMk"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, print_outputs=False):\n",
        "    model = model.eval()\n",
        "    \n",
        "    losses_fn = []\n",
        "    losses_adv = []\n",
        "    correct_pred_fn = 0\n",
        "    correct_pred_adv = 0\n",
        "    \n",
        "    n_examples = len(data_loader) * data_loader.batch_size\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.to(device)\n",
        "        loss_fn.to(device)\n",
        "        for news_item, input_ids, attention_mask, targets, keywords, item_id in data_loader:\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            targets = targets.to(device)\n",
        "            if model.use_adv:\n",
        "                keywords = keywords.to(device)\n",
        "\n",
        "            fn_outputs, adv_outputs = model(input_ids, attention_mask)\n",
        "            if print_outputs:\n",
        "                print(fn_outputs, adv_outputs)\n",
        "            _, fn_preds = torch.max(fn_outputs, dim=1)\n",
        "            fn_loss = loss_fn(fn_outputs, targets)\n",
        "            losses_fn.append(fn_loss.item())\n",
        "            correct_pred_fn += torch.sum(fn_preds == targets)\n",
        "\n",
        "            if model.use_adv and adv_outputs is not None:\n",
        "                _, adv_preds = torch.max(adv_outputs, dim=1)\n",
        "                adv_loss = loss_fn(adv_outputs, keywords)\n",
        "                losses_adv.append(adv_loss.item())\n",
        "                correct_pred_adv += torch.sum(adv_preds == keywords)\n",
        "\n",
        "    return {\n",
        "        \"acc_pred_fn\": correct_pred_fn.double().item() / n_examples if correct_pred_fn is not 0 else 0,\n",
        "        \"avg_loss_fn\": np.mean(losses_fn) if len(losses_fn) > 0 else 0,\n",
        "        \"acc_pred_adv\": correct_pred_adv.double().item() / n_examples if correct_pred_adv is not 0 else 0,\n",
        "        \"avg_loss_adv\": np.mean(losses_adv) if len(losses_adv) > 0 else 0\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOuXfVV-qfnu"
      },
      "source": [
        "# Training Function\n",
        "\n",
        "def train(model,\n",
        "          optimizer,\n",
        "          criterion,\n",
        "          train_loader,\n",
        "          val_loader,\n",
        "          num_epochs):\n",
        "    \n",
        "    adversarial = model.use_adv\n",
        "\n",
        "    global_step = 0\n",
        "    total_steps = num_epochs * len(train_loader)\n",
        "\n",
        "    general_losses = []\n",
        "\n",
        "    fn_acc = []\n",
        "    fn_losses = []\n",
        "    fn_correct_predictions = 0\n",
        "\n",
        "    adv_losses, adv_correct_predictions, adv_acc = None, None, None\n",
        "    if adversarial:\n",
        "        adv_losses = []\n",
        "        adv_correct_predictions = 0\n",
        "        adv_acc = []\n",
        "\n",
        "    model.to(device)\n",
        "    criterion.to(device)\n",
        "\n",
        "    print_digits = len(str(num_epochs))\n",
        "\n",
        "    # training loop\n",
        "    mark_batch_every = max(int(len(train_loader) / 100), 1)\n",
        "    model.train()\n",
        "    print(\".\" * (100 + len(\"EPOCH #   \") + print_digits + 1))\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"EPOCH #\", str(epoch).zfill(print_digits), end=\" \")\n",
        "        model.train()\n",
        "        \n",
        "        epoch_general_losses, epoch_fn_losses, epoch_adv_losses = [], [], []\n",
        "        epoch_fn_acc, epoch_adv_acc = [], []\n",
        "        \n",
        "        batch = 0\n",
        "        epoch_start = int(time() * 1_000)\n",
        "        for news_item, input_ids, attention_mask, targets, keywords, item_id in train_loader:\n",
        "            if batch % mark_batch_every == 0:\n",
        "                print(\".\", end=\"\")\n",
        "            batch += 1\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            targets = targets.to(device)\n",
        "            if adversarial:\n",
        "                keywords = keywords.to(device)\n",
        "\n",
        "            fn_outputs, adv_outputs = model(input_ids, attention_mask)\n",
        "            _, fn_preds = torch.max(fn_outputs, dim=1)\n",
        "\n",
        "            fn_loss = criterion(fn_outputs, targets)\n",
        "            epoch_fn_losses.append(fn_loss.item())\n",
        "\n",
        "            fn_correct_predictions += torch.sum(fn_preds == targets)\n",
        "\n",
        "            fn_accuracy = (targets == fn_preds.squeeze()).float().mean()\n",
        "            epoch_fn_acc.append(fn_accuracy.item())\n",
        "            \n",
        "            loss = fn_loss\n",
        "            \n",
        "            if adversarial and adv_outputs is not None:\n",
        "                _, adv_preds = torch.max(adv_outputs, dim=1)\n",
        "\n",
        "                adv_loss = criterion(adv_outputs, keywords)\n",
        "                epoch_adv_losses.append(adv_loss.item())\n",
        "\n",
        "                adv_correct_predictions += torch.sum(adv_preds == keywords)\n",
        "\n",
        "                adv_accuracy = (keywords == adv_preds.squeeze()).float().mean()\n",
        "                epoch_adv_acc.append(adv_accuracy.item())\n",
        "\n",
        "                loss = fn_loss + adv_loss\n",
        "\n",
        "            epoch_general_losses.append(loss.item())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        epoch_end = int(time() * 1_000)\n",
        "\n",
        "        general_losses.append(np.mean(epoch_general_losses))\n",
        "\n",
        "        fn_losses.append(np.mean(epoch_fn_losses))\n",
        "        fn_acc.append(np.mean(epoch_fn_acc))\n",
        "\n",
        "        if adversarial:\n",
        "            adv_losses.append(np.mean(epoch_adv_losses))\n",
        "            adv_acc.append(np.mean(epoch_adv_acc))\n",
        "\n",
        "        print(\" -- \", (epoch_end - epoch_start), \"ms\", sep=\"\")\n",
        "        print(\"LOSS:\", general_losses[-1])\n",
        "        print(\"LOSS FN:\", fn_losses[-1])\n",
        "        if adversarial:\n",
        "            print(\"LOSS ADV:\", adv_losses[-1])\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            print(\"Evaluating for epoch #\", epoch)\n",
        "            \n",
        "            train_eval_res = eval_model(model, train_loader, criterion, device)\n",
        "            val_eval_res = eval_model(model, val_loader, criterion, device)\n",
        "            \n",
        "            print(\n",
        "                'Epoch [{}/{}]: Train: {:.4f}, {:.4f} {}; Val: {:.4f}, {:4f} {};'.format(\n",
        "                    epoch, num_epochs,\n",
        "                    train_eval_res[\"acc_pred_fn\"], train_eval_res[\"avg_loss_fn\"],\n",
        "                    \"({:.4f}, {:.4f})\".format(train_eval_res[\"acc_pred_adv\"], train_eval_res[\"avg_loss_adv\"]) if adversarial else \"\",\n",
        "                    val_eval_res[\"acc_pred_fn\"], val_eval_res[\"avg_loss_fn\"],\n",
        "                    \"({:.4f}, {:.4f})\".format(val_eval_res[\"acc_pred_adv\"], val_eval_res[\"avg_loss_adv\"]) if adversarial else \"\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "            model.train()\n",
        "            model.to(device)\n",
        "            criterion.to(device)\n",
        "    print('Finished Training!')\n",
        "\n",
        "    log_data = {\n",
        "        \"general_losses\":           general_losses,\n",
        "        \"fn_accuracies\":            fn_acc,\n",
        "        \"fn_losses\":                fn_losses,\n",
        "        \"fn_correct_predictions\":   fn_correct_predictions,\n",
        "    }\n",
        "\n",
        "    if adversarial:\n",
        "        log_data.update({\n",
        "            \"adv_losses\":               adv_losses,\n",
        "            \"adv_correct_predictions\":  adv_correct_predictions,\n",
        "            \"adv_accuracies\":           adv_acc,\n",
        "        })\n",
        "\n",
        "\n",
        "    return model, log_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSws4SE7zXq4"
      },
      "source": [
        "def get_predictions(model, data_loader, results_df, col_prefix, device):\n",
        "    model = model.eval()\n",
        "\n",
        "    COL_PRED_FAKE = col_prefix + \"_pred_fake\"\n",
        "    COL_PRED_KEYWORD = col_prefix + \"_pred_keyword\"\n",
        "\n",
        "    results_df[COL_PRED_FAKE] = pd.Series(dtype=np.int32)\n",
        "    if model.use_adv:\n",
        "        results_df[COL_PRED_KEYWORD] = pd.Series(dtype=np.int32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.to(device)\n",
        "        for news_item, input_ids, attention_mask, targets, keywords, item_id in data_loader:\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            targets = targets.to(device)\n",
        "            if model.use_adv:\n",
        "                keywords = keywords.to(device)\n",
        "\n",
        "            fn_outputs, adv_outputs = model(input_ids, attention_mask)\n",
        "\n",
        "            _, fn_preds = torch.max(fn_outputs, dim=1)\n",
        "\n",
        "            adv_preds = None\n",
        "            if model.use_adv and adv_outputs is not None:\n",
        "                _, adv_preds = torch.max(adv_outputs, dim=1)\n",
        "\n",
        "            for i in range(len(news_item)):\n",
        "                if results_df.title_content[item_id[i].item()] == news_item[i]:\n",
        "                    results_df[COL_PRED_FAKE].iat[item_id[i].item()] = fn_preds[i].item()\n",
        "                    if adv_preds is not None:\n",
        "                        results_df[COL_PRED_KEYWORD].iat[item_id[i].item()] = adv_preds[i].item()\n",
        "\n",
        "    return results_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6Pv3XqFLd5P"
      },
      "source": [
        "## Training & Eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71LtkDVeti2G"
      },
      "source": [
        "LEARNING_RATE = 1e-06\n",
        "EPOCHS = 10\n",
        "OUTPUT_LABEL = \"final-\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1YLVI_sCue5"
      },
      "source": [
        "model_num = 1\n",
        "def get_run_label(prefix=OUTPUT_LABEL):\n",
        "    return prefix + str(model_num).zfill(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_Li7ol4HLeA"
      },
      "source": [
        "### SIMPLE - UNBALANCED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eco5qMSrHQla"
      },
      "source": [
        "model = FANN(use_adv=False)\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, list(model.parameters())), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5CBdummHQla",
        "outputId": "dd5c798e-3002-4326-fd2a-a9e809481a10"
      },
      "source": [
        "SIMPLE_SAVE_PATH = destination_folder + \"fann_model_simple-\" + get_run_label() + \".pytorch\"\n",
        "if path.exists(SIMPLE_SAVE_PATH):\n",
        "    model = torch.load(SIMPLE_SAVE_PATH)\n",
        "    print(\"Loaded model from\", SIMPLE_SAVE_PATH)\n",
        "else:\n",
        "    _, log = train(\n",
        "        model, optimizer, criterion, \n",
        "        unbal_train_data_loader, unbal_val_data_loader,\n",
        "        num_epochs=EPOCHS\n",
        "    )\n",
        "    pickle.dump(log, open(destination_folder + \"simple_model_train_log.pickle\", \"wb\" ))\n",
        "    torch.save(model, SIMPLE_SAVE_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from /content/drive/My Drive/Projects/Academic/NN/final_output/fann_model_simple-final-001.pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8in_5mO-6I_"
      },
      "source": [
        "res = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCMo9hlbyH_1",
        "outputId": "ffa81423-1626-42bf-e752-78ec3730a931"
      },
      "source": [
        "res[\"train\"] = eval_model(model, unbal_train_data_loader, criterion, device)\n",
        "res[\"train\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc_pred_adv': 0,\n",
              " 'acc_pred_fn': 0.8909166666666667,\n",
              " 'avg_loss_adv': 0,\n",
              " 'avg_loss_fn': 0.41858205236991247}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04V60axlHQld",
        "outputId": "5ae3e934-c746-479e-c1be-c8682baa8e1e"
      },
      "source": [
        "res[\"validation\"] = eval_model(model, unbal_val_data_loader, criterion, device)\n",
        "res[\"validation\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc_pred_adv': 0,\n",
              " 'acc_pred_fn': 0.8832386363636363,\n",
              " 'avg_loss_adv': 0,\n",
              " 'avg_loss_fn': 0.4270823427221992}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmRUeENLHQld",
        "outputId": "e5cc90a9-7d84-4508-b36b-dcd5bb54beab"
      },
      "source": [
        "res[\"test\"] = eval_model(model, unbal_test_data_loader, criterion, device)\n",
        "res[\"test\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc_pred_adv': 0,\n",
              " 'acc_pred_fn': 0.8711656441717791,\n",
              " 'avg_loss_adv': 0,\n",
              " 'avg_loss_fn': 0.43611402440899966}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x20nXpaa_ln2"
      },
      "source": [
        "pickle.dump(res, open(destination_folder + \"simple_model_eval_res.pickle\", \"wb\" ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aLefReVSHQld",
        "outputId": "5dc89329-f402-4319-d643-d9615e26d9b4"
      },
      "source": [
        "get_predictions(model, unbal_train_data_loader, unbal_data_train, 'su', device)\n",
        "get_predictions(model, unbal_test_data_loader, unbal_data_test, 'su', device)\n",
        "get_predictions(model, unbal_val_data_loader, unbal_data_val, 'su', device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>domain</th>\n",
              "      <th>type</th>\n",
              "      <th>content</th>\n",
              "      <th>updated_at</th>\n",
              "      <th>title</th>\n",
              "      <th>fake</th>\n",
              "      <th>has_mk_climate change</th>\n",
              "      <th>has_mk_business</th>\n",
              "      <th>has_mk_energy</th>\n",
              "      <th>has_mk_renewables</th>\n",
              "      <th>has_mk_health</th>\n",
              "      <th>has_mk_food</th>\n",
              "      <th>has_mk_biodiversity</th>\n",
              "      <th>has_mk_sustainable business</th>\n",
              "      <th>has_mk_coal</th>\n",
              "      <th>has_mk_fracking</th>\n",
              "      <th>has_mk_politics</th>\n",
              "      <th>has_mk_science</th>\n",
              "      <th>has_mk_china</th>\n",
              "      <th>has_mk_ebola</th>\n",
              "      <th>has_mk_cuba</th>\n",
              "      <th>has_mk_cop21</th>\n",
              "      <th>has_mk_pipelines</th>\n",
              "      <th>has_mk_russia</th>\n",
              "      <th>has_mk_tips</th>\n",
              "      <th>has_mk_transportation</th>\n",
              "      <th>has_mk_donald trump</th>\n",
              "      <th>has_mk_united states</th>\n",
              "      <th>has_mk_barack obama</th>\n",
              "      <th>has_mk_hillary clinton</th>\n",
              "      <th>has_mk_economics</th>\n",
              "      <th>has_mk_news</th>\n",
              "      <th>has_mk_big government</th>\n",
              "      <th>has_mk_finance</th>\n",
              "      <th>has_mk_markets</th>\n",
              "      <th>has_mk_analysis</th>\n",
              "      <th>has_mk_zerohedge</th>\n",
              "      <th>has_mk_zero hedge</th>\n",
              "      <th>has_mk_wikileaks</th>\n",
              "      <th>has_mk_syria</th>\n",
              "      <th>...</th>\n",
              "      <th>has_author_carl arbogast</th>\n",
              "      <th>has_author_the onion</th>\n",
              "      <th>has_author_el mito</th>\n",
              "      <th>has_author_egberto willies</th>\n",
              "      <th>has_author_james phibbs</th>\n",
              "      <th>has_author_martin walsh</th>\n",
              "      <th>has_author_israel shamir</th>\n",
              "      <th>has_author_p. ghose</th>\n",
              "      <th>has_author_andrea ruth</th>\n",
              "      <th>has_author_brandon morse</th>\n",
              "      <th>has_author_kira davis</th>\n",
              "      <th>has_author_paul kersey</th>\n",
              "      <th>has_author_robert roth</th>\n",
              "      <th>has_author_goyim must die</th>\n",
              "      <th>has_author_dr. eowyn</th>\n",
              "      <th>has_author_pamela geller</th>\n",
              "      <th>has_author_joan mccarter</th>\n",
              "      <th>has_author_kerry eleveld</th>\n",
              "      <th>has_author_sexy-author-bio</th>\n",
              "      <th>has_author_border-color</th>\n",
              "      <th>has_author_border-top-width</th>\n",
              "      <th>has_author_michael snyder</th>\n",
              "      <th>has_author_ed tracey</th>\n",
              "      <th>has_author_because without america</th>\n",
              "      <th>has_author_there is no free world.</th>\n",
              "      <th>has_author_joe cunningham</th>\n",
              "      <th>has_author_sara r</th>\n",
              "      <th>has_author_charles perrin</th>\n",
              "      <th>has_author_follow on twitter</th>\n",
              "      <th>has_author_denise oliver velez</th>\n",
              "      <th>has_author_c.j. hopkins</th>\n",
              "      <th>has_author_mark anderson</th>\n",
              "      <th>has_author_nick kollerstrom</th>\n",
              "      <th>sample_weights</th>\n",
              "      <th>title_content</th>\n",
              "      <th>content_length</th>\n",
              "      <th>title_length</th>\n",
              "      <th>total_length</th>\n",
              "      <th>keyword</th>\n",
              "      <th>su_pred_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>washingtonexaminer.com</td>\n",
              "      <td>political</td>\n",
              "      <td>President Trump called Camp David a \"very spec...</td>\n",
              "      <td>2018-02-07 23:39:33.852696</td>\n",
              "      <td>Trump calls Camp David 'a very special place' ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1540427</td>\n",
              "      <td>Trump calls Camp David 'a very special place' ...</td>\n",
              "      <td>159</td>\n",
              "      <td>13</td>\n",
              "      <td>159</td>\n",
              "      <td>politics</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>zerohedge.com</td>\n",
              "      <td>conspiracy</td>\n",
              "      <td>The problem with government is it elevates peo...</td>\n",
              "      <td>2018-02-07 23:39:33.852696</td>\n",
              "      <td>bearsecutor</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1702435</td>\n",
              "      <td>bearsecutor &lt;ENDTITLE&gt; \\n The problem with gov...</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>politics</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sputniknews.com</td>\n",
              "      <td>bias</td>\n",
              "      <td>The Gold Rush didn't only take human lives but...</td>\n",
              "      <td>2018-02-07 23:39:33.852696</td>\n",
              "      <td>Apocalyptic Tourism: Top-7 Blood-Curdling Ghos...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1702435</td>\n",
              "      <td>Apocalyptic Tourism: Top-7 Blood-Curdling Ghos...</td>\n",
              "      <td>150</td>\n",
              "      <td>6</td>\n",
              "      <td>150</td>\n",
              "      <td>china</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>washingtonexaminer.com</td>\n",
              "      <td>political</td>\n",
              "      <td>The Environmental Protection Agency on Thursda...</td>\n",
              "      <td>2018-02-02 01:19:41.756664</td>\n",
              "      <td>EPA levels record $27 million fine for renewab...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1540427</td>\n",
              "      <td>EPA levels record $27 million fine for renewab...</td>\n",
              "      <td>376</td>\n",
              "      <td>10</td>\n",
              "      <td>376</td>\n",
              "      <td>politics</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dailycaller.com</td>\n",
              "      <td>political</td>\n",
              "      <td>Obamas mishandling of economy has voters look...</td>\n",
              "      <td>2018-02-07 23:39:33.852696</td>\n",
              "      <td>The DC Morning  July 13, 2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1540427</td>\n",
              "      <td>The DC Morning  July 13, 2010 &lt;ENDTITLE&gt; \\n O...</td>\n",
              "      <td>800</td>\n",
              "      <td>7</td>\n",
              "      <td>800</td>\n",
              "      <td>politics</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3511</th>\n",
              "      <td>sputniknews.com</td>\n",
              "      <td>bias</td>\n",
              "      <td>US President Donald Trump's solo press confere...</td>\n",
              "      <td>2018-02-07 23:39:33.852696</td>\n",
              "      <td>Trump's Presser: 'A Brilliant Takedown of Corr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1702435</td>\n",
              "      <td>Trump's Presser: 'A Brilliant Takedown of Corr...</td>\n",
              "      <td>975</td>\n",
              "      <td>12</td>\n",
              "      <td>975</td>\n",
              "      <td>russia</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3512</th>\n",
              "      <td>zerohedge.com</td>\n",
              "      <td>conspiracy</td>\n",
              "      <td>If you are actively involved in the markets as...</td>\n",
              "      <td>2018-02-07 23:39:33.852696</td>\n",
              "      <td>Ignoring This Four Letter Word Means Losing Mo...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1702435</td>\n",
              "      <td>Ignoring This Four Letter Word Means Losing Mo...</td>\n",
              "      <td>372</td>\n",
              "      <td>10</td>\n",
              "      <td>372</td>\n",
              "      <td>politics</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3513</th>\n",
              "      <td>coasttocoastam.com</td>\n",
              "      <td>unreliable</td>\n",
              "      <td>Date Friday - June 8, 2007\\n\\nHost George Noor...</td>\n",
              "      <td>2018-02-02 01:19:41.756664</td>\n",
              "      <td>Souls for Sale!</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1702435</td>\n",
              "      <td>Souls for Sale! &lt;ENDTITLE&gt; \\n Date Friday - Ju...</td>\n",
              "      <td>233</td>\n",
              "      <td>3</td>\n",
              "      <td>233</td>\n",
              "      <td>science</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3514</th>\n",
              "      <td>sputniknews.com</td>\n",
              "      <td>bias</td>\n",
              "      <td>Air pollutant particulate matter (PM), which a...</td>\n",
              "      <td>2018-02-02 01:19:41.756664</td>\n",
              "      <td>Air Pollution Cuts Solar Power Generation By 2...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1702435</td>\n",
              "      <td>Air Pollution Cuts Solar Power Generation By 2...</td>\n",
              "      <td>286</td>\n",
              "      <td>11</td>\n",
              "      <td>286</td>\n",
              "      <td>china</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3515</th>\n",
              "      <td>sputniknews.com</td>\n",
              "      <td>bias</td>\n",
              "      <td>The visit of French delegation will give the w...</td>\n",
              "      <td>2018-02-07 23:39:33.852696</td>\n",
              "      <td>French Lawmakers Visit to Give World Candid De...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1702435</td>\n",
              "      <td>French Lawmakers Visit to Give World Candid De...</td>\n",
              "      <td>182</td>\n",
              "      <td>12</td>\n",
              "      <td>182</td>\n",
              "      <td>russia</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3516 rows  313 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      domain        type  ...   keyword su_pred_fake\n",
              "0     washingtonexaminer.com   political  ...  politics          0.0\n",
              "1              zerohedge.com  conspiracy  ...  politics          1.0\n",
              "2            sputniknews.com        bias  ...     china          1.0\n",
              "3     washingtonexaminer.com   political  ...  politics          0.0\n",
              "4            dailycaller.com   political  ...  politics          0.0\n",
              "...                      ...         ...  ...       ...          ...\n",
              "3511         sputniknews.com        bias  ...    russia          0.0\n",
              "3512           zerohedge.com  conspiracy  ...  politics          0.0\n",
              "3513      coasttocoastam.com  unreliable  ...   science          0.0\n",
              "3514         sputniknews.com        bias  ...     china          1.0\n",
              "3515         sputniknews.com        bias  ...    russia          1.0\n",
              "\n",
              "[3516 rows x 313 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79D-0_Bm_0cU"
      },
      "source": [
        "unbal_data_train.to_csv(destination_folder + \"train_pred_outputs_simple.csv\", columns=[\"su_pred_fake\"])\n",
        "unbal_data_test.to_csv(destination_folder + \"test_pred_outputs_simple.csv\", columns=[\"su_pred_fake\"])\n",
        "unbal_data_val.to_csv(destination_folder + \"val_pred_outputs_simple.csv\", columns=[\"su_pred_fake\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc9TBe57KXGE"
      },
      "source": [
        "### ADVERSARIAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSvu5BpkKSHo"
      },
      "source": [
        "model_adv = FANN(adv_classes=ADV_CLASSES, use_adv=True)\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, list(model_adv.parameters())), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLrZjtWhKSHo",
        "outputId": "06585f61-f098-4a34-b940-2943e24f574f"
      },
      "source": [
        "ADV_SAVE_PATH = destination_folder + \"fann_model_adv-\" + get_run_label() + \".pytorch\"\n",
        "if path.exists(ADV_SAVE_PATH):\n",
        "    model_adv = torch.load(ADV_SAVE_PATH)\n",
        "    print(\"Loaded model from\", ADV_SAVE_PATH)\n",
        "else:\n",
        "    _, log_adv = train(\n",
        "        model_adv, optimizer, criterion, \n",
        "        unbal_train_data_loader, unbal_val_data_loader,\n",
        "        num_epochs=EPOCHS\n",
        "    )\n",
        "    pickle.dump(log_adv, open(destination_folder + \"adversarial_model_train_log.pickle\", \"wb\"))\n",
        "    torch.save(model_adv, ADV_SAVE_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from /content/drive/My Drive/Projects/Academic/NN/final_output/fann_model_adv-final-001.pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX-4ht6D-bRa"
      },
      "source": [
        "res_adv = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6yJhPQvyjmy",
        "outputId": "947f262f-2ad5-4422-b9ac-98aaa7e18422"
      },
      "source": [
        "res_adv[\"train\"] = eval_model(model_adv, unbal_train_data_loader, criterion, device)\n",
        "res_adv[\"train\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc_pred_adv': 0.00175,\n",
              " 'acc_pred_fn': 0.91025,\n",
              " 'avg_loss_adv': 3.0069282801946002,\n",
              " 'avg_loss_fn': 0.4402759485046069}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEpgErB1KSHp",
        "outputId": "a9c2d368-4e76-4ff0-e299-6d1a0c34e6c7"
      },
      "source": [
        "res_adv[\"validation\"] = eval_model(model_adv, unbal_val_data_loader, criterion, device)\n",
        "res_adv[\"validation\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc_pred_adv': 0.008238636363636363,\n",
              " 'acc_pred_fn': 0.8897727272727273,\n",
              " 'avg_loss_adv': 3.0065241260962052,\n",
              " 'avg_loss_fn': 0.4533728661862287}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXumF4CZKSHq",
        "outputId": "cdecff1b-0193-4238-8c62-c3b9edcfdf32"
      },
      "source": [
        "res_adv[\"test\"] = eval_model(model_adv, unbal_test_data_loader, criterion, device)\n",
        "res_adv[\"test\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc_pred_adv': 0.006134969325153374,\n",
              " 'acc_pred_fn': 0.8908486707566462,\n",
              " 'avg_loss_adv': 3.0059133702260583,\n",
              " 'avg_loss_fn': 0.4539998555232167}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18FFn9B5Agcr"
      },
      "source": [
        "pickle.dump(res_adv, open(destination_folder + \"adversarial_model_eval_res.pickle\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Har4AxOlKSHq",
        "outputId": "d173d91b-1b31-460e-f134-6d444e412f44"
      },
      "source": [
        "get_predictions(model_adv, unbal_train_data_loader, unbal_data_train, 'au', device)\n",
        "get_predictions(model_adv, unbal_test_data_loader, unbal_data_test, 'au', device)\n",
        "get_predictions(model_adv, unbal_val_data_loader, unbal_data_val, 'au', device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>domain</th>\n",
              "      <th>type</th>\n",
              "      <th>content</th>\n",
              "      <th>updated_at</th>\n",
              "      <th>title</th>\n",
              "      <th>fake</th>\n",
              "      <th>has_mk_climate change</th>\n",
              "      <th>has_mk_business</th>\n",
              "      <th>has_mk_energy</th>\n",
              "      <th>has_mk_renewables</th>\n",
              "      <th>has_mk_health</th>\n",
              "      <th>has_mk_food</th>\n",
              "      <th>has_mk_biodiversity</th>\n",
              "      <th>has_mk_sustainable business</th>\n",
              "      <th>has_mk_coal</th>\n",
              "      <th>has_mk_fracking</th>\n",
              "      <th>has_mk_politics</th>\n",
              "      <th>has_mk_science</th>\n",
              "      <th>has_mk_china</th>\n",
              "      <th>has_mk_ebola</th>\n",
              "      <th>has_mk_cuba</th>\n",
              "      <th>has_mk_cop21</th>\n",
              "      <th>has_mk_pipelines</th>\n",
              "      <th>has_mk_russia</th>\n",
              "      <th>has_mk_tips</th>\n",
              "      <th>has_mk_transportation</th>\n",
              "      <th>has_mk_donald trump</th>\n",
              "      <th>has_mk_united states</th>\n",
              "      <th>has_mk_barack obama</th>\n",
              "      <th>has_mk_hillary clinton</th>\n",
              "      <th>has_mk_economics</th>\n",
              "      <th>has_mk_news</th>\n",
              "      <th>has_mk_big government</th>\n",
              "      <th>has_mk_finance</th>\n",
              "      <th>has_mk_markets</th>\n",
              "      <th>has_mk_analysis</th>\n",
              "      <th>has_mk_zerohedge</th>\n",
              "      <th>has_mk_zero hedge</th>\n",
              "      <th>has_mk_wikileaks</th>\n",
              "      <th>has_mk_syria</th>\n",
              "      <th>...</th>\n",
              "      <th>has_author_el mito</th>\n",
              "      <th>has_author_egberto willies</th>\n",
              "      <th>has_author_james phibbs</th>\n",
              "      <th>has_author_martin walsh</th>\n",
              "      <th>has_author_israel shamir</th>\n",
              "      <th>has_author_p. ghose</th>\n",
              "      <th>has_author_andrea ruth</th>\n",
              "      <th>has_author_brandon morse</th>\n",
              "      <th>has_author_kira davis</th>\n",
              "      <th>has_author_paul kersey</th>\n",
              "      <th>has_author_robert roth</th>\n",
              "      <th>has_author_goyim must die</th>\n",
              "      <th>has_author_dr. eowyn</th>\n",
              "      <th>has_author_pamela geller</th>\n",
              "      <th>has_author_joan mccarter</th>\n",
              "      <th>has_author_kerry eleveld</th>\n",
              "      <th>has_author_sexy-author-bio</th>\n",
              "      <th>has_author_border-color</th>\n",
              "      <th>has_author_border-top-width</th>\n",
              "      <th>has_author_michael snyder</th>\n",
              "      <th>has_author_ed tracey</th>\n",
              "      <th>has_author_because without america</th>\n",
              "      <th>has_author_there is no free world.</th>\n",
              "      <th>has_author_joe cunningham</th>\n",
              "      <th>has_author_sara r</th>\n",
              "      <th>has_author_charles perrin</th>\n",
              "      <th>has_author_follow on twitter</th>\n",
              "      <th>has_author_denise oliver velez</th>\n",
              "      <th>has_author_c.j. hopkins</th>\n",
              "      <th>has_author_mark anderson</th>\n",
              "      <th>has_author_nick kollerstrom</th>\n",
              "      <th>sample_weights</th>\n",
              "      <th>title_content</th>\n",
              "      <th>content_length</th>\n",
              "      <th>title_length</th>\n",
              "      <th>total_length</th>\n",
              "      <th>keyword</th>\n",
              "      <th>su_pred_fake</th>\n",
              "      <th>au_pred_fake</th>\n",
              "      <th>au_pred_keyword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>washingtonexaminer.com</td>\n",
              "      <td>political</td>\n",
              "      <td>President Trump called Camp David a \"very spec...</td>\n",
              "      <td>2018-02-07 23:39:33.852696</td>\n",
              "      <td>Trump calls Camp David 'a very special place' ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1540427</td>\n",
              "      <td>Trump calls Camp David 'a very special place' ...</td>\n",
              "      <td>159</td>\n",
              "      <td>13</td>\n",
              "      <td>159</td>\n",
              "      <td>politics</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>zerohedge.com</td>\n",
              "      <td>conspiracy</td>\n",
              "      <td>The problem with government is it elevates peo...</td>\n",
              "      <td>2018-02-07 23:39:33.852696</td>\n",
              "      <td>bearsecutor</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1702435</td>\n",
              "      <td>bearsecutor &lt;ENDTITLE&gt; \\n The problem with gov...</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>politics</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sputniknews.com</td>\n",
              "      <td>bias</td>\n",
              "      <td>The Gold Rush didn't only take human lives but...</td>\n",
              "      <td>2018-02-07 23:39:33.852696</td>\n",
              "      <td>Apocalyptic Tourism: Top-7 Blood-Curdling Ghos...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1702435</td>\n",
              "      <td>Apocalyptic Tourism: Top-7 Blood-Curdling Ghos...</td>\n",
              "      <td>150</td>\n",
              "      <td>6</td>\n",
              "      <td>150</td>\n",
              "      <td>china</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>washingtonexaminer.com</td>\n",
              "      <td>political</td>\n",
              "      <td>The Environmental Protection Agency on Thursda...</td>\n",
              "      <td>2018-02-02 01:19:41.756664</td>\n",
              "      <td>EPA levels record $27 million fine for renewab...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1540427</td>\n",
              "      <td>EPA levels record $27 million fine for renewab...</td>\n",
              "      <td>376</td>\n",
              "      <td>10</td>\n",
              "      <td>376</td>\n",
              "      <td>politics</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dailycaller.com</td>\n",
              "      <td>political</td>\n",
              "      <td>Obamas mishandling of economy has voters look...</td>\n",
              "      <td>2018-02-07 23:39:33.852696</td>\n",
              "      <td>The DC Morning  July 13, 2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1540427</td>\n",
              "      <td>The DC Morning  July 13, 2010 &lt;ENDTITLE&gt; \\n O...</td>\n",
              "      <td>800</td>\n",
              "      <td>7</td>\n",
              "      <td>800</td>\n",
              "      <td>politics</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3511</th>\n",
              "      <td>sputniknews.com</td>\n",
              "      <td>bias</td>\n",
              "      <td>US President Donald Trump's solo press confere...</td>\n",
              "      <td>2018-02-07 23:39:33.852696</td>\n",
              "      <td>Trump's Presser: 'A Brilliant Takedown of Corr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1702435</td>\n",
              "      <td>Trump's Presser: 'A Brilliant Takedown of Corr...</td>\n",
              "      <td>975</td>\n",
              "      <td>12</td>\n",
              "      <td>975</td>\n",
              "      <td>russia</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3512</th>\n",
              "      <td>zerohedge.com</td>\n",
              "      <td>conspiracy</td>\n",
              "      <td>If you are actively involved in the markets as...</td>\n",
              "      <td>2018-02-07 23:39:33.852696</td>\n",
              "      <td>Ignoring This Four Letter Word Means Losing Mo...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1702435</td>\n",
              "      <td>Ignoring This Four Letter Word Means Losing Mo...</td>\n",
              "      <td>372</td>\n",
              "      <td>10</td>\n",
              "      <td>372</td>\n",
              "      <td>politics</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3513</th>\n",
              "      <td>coasttocoastam.com</td>\n",
              "      <td>unreliable</td>\n",
              "      <td>Date Friday - June 8, 2007\\n\\nHost George Noor...</td>\n",
              "      <td>2018-02-02 01:19:41.756664</td>\n",
              "      <td>Souls for Sale!</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1702435</td>\n",
              "      <td>Souls for Sale! &lt;ENDTITLE&gt; \\n Date Friday - Ju...</td>\n",
              "      <td>233</td>\n",
              "      <td>3</td>\n",
              "      <td>233</td>\n",
              "      <td>science</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3514</th>\n",
              "      <td>sputniknews.com</td>\n",
              "      <td>bias</td>\n",
              "      <td>Air pollutant particulate matter (PM), which a...</td>\n",
              "      <td>2018-02-02 01:19:41.756664</td>\n",
              "      <td>Air Pollution Cuts Solar Power Generation By 2...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1702435</td>\n",
              "      <td>Air Pollution Cuts Solar Power Generation By 2...</td>\n",
              "      <td>286</td>\n",
              "      <td>11</td>\n",
              "      <td>286</td>\n",
              "      <td>china</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3515</th>\n",
              "      <td>sputniknews.com</td>\n",
              "      <td>bias</td>\n",
              "      <td>The visit of French delegation will give the w...</td>\n",
              "      <td>2018-02-07 23:39:33.852696</td>\n",
              "      <td>French Lawmakers Visit to Give World Candid De...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1702435</td>\n",
              "      <td>French Lawmakers Visit to Give World Candid De...</td>\n",
              "      <td>182</td>\n",
              "      <td>12</td>\n",
              "      <td>182</td>\n",
              "      <td>russia</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3516 rows  315 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      domain        type  ... au_pred_fake au_pred_keyword\n",
              "0     washingtonexaminer.com   political  ...          0.0            11.0\n",
              "1              zerohedge.com  conspiracy  ...          1.0            18.0\n",
              "2            sputniknews.com        bias  ...          1.0            18.0\n",
              "3     washingtonexaminer.com   political  ...          0.0            11.0\n",
              "4            dailycaller.com   political  ...          0.0            11.0\n",
              "...                      ...         ...  ...          ...             ...\n",
              "3511         sputniknews.com        bias  ...          1.0            18.0\n",
              "3512           zerohedge.com  conspiracy  ...          0.0            11.0\n",
              "3513      coasttocoastam.com  unreliable  ...          1.0            18.0\n",
              "3514         sputniknews.com        bias  ...          1.0            18.0\n",
              "3515         sputniknews.com        bias  ...          1.0            18.0\n",
              "\n",
              "[3516 rows x 315 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Moa2YlsGlrHR",
        "outputId": "3d61a6b0-7df1-4b8a-b625-6ccfe842d3ba"
      },
      "source": [
        "unbal_data_train[\"au_pred_keyword\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18., nan, 11.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1fRl6iVA-qv"
      },
      "source": [
        "def convert_to_keyword_name(k, data_loader):\n",
        "    return data_loader.dataset.int_2_keyword.get(int(k) if not np.isnan(k) else -1, \"unk\")\n",
        "    \n",
        "unbal_data_train[\"au_pred_keyword_name\"] = unbal_data_train[\"au_pred_keyword\"].apply(lambda k: convert_to_keyword_name(k, unbal_train_data_loader))\n",
        "unbal_data_test[\"au_pred_keyword_name\"] = unbal_data_test[\"au_pred_keyword\"].apply(lambda k: convert_to_keyword_name(k, unbal_train_data_loader))\n",
        "unbal_data_val[\"au_pred_keyword_name\"] = unbal_data_val[\"au_pred_keyword\"].apply(lambda k: convert_to_keyword_name(k, unbal_train_data_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gySEXirwCIEQ",
        "outputId": "b162ef9a-ed20-42f2-aafe-291bc24d7dd2"
      },
      "source": [
        "unbal_data_train[\"au_pred_keyword_name\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['fracking', 'unk', 'renewables'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jU28RO3Ap-A"
      },
      "source": [
        "unbal_data_train.to_csv(destination_folder + \"train_pred_outputs_adversarial.csv\", columns=[\"au_pred_fake\", \"au_pred_keyword\", \"au_pred_keyword_name\"])\n",
        "unbal_data_test.to_csv(destination_folder + \"test_pred_outputs_adversarial.csv\", columns=[\"au_pred_fake\", \"au_pred_keyword\", \"au_pred_keyword_name\"])\n",
        "unbal_data_val.to_csv(destination_folder + \"val_pred_outputs_adversarial.csv\", columns=[\"au_pred_fake\", \"au_pred_keyword\", \"au_pred_keyword_name\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h19puB1SLZUx"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19J0SKfqfKKp"
      },
      "source": [
        "### Metrics Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DaG4kpx9vCn"
      },
      "source": [
        "# Remove samples unused in training\n",
        "unbal_data_train_full = unbal_data_train\n",
        "unbal_data_train = unbal_data_train.dropna(subset=[\"su_pred_fake\", \"au_pred_fake\", \"au_pred_keyword\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LreL0cx3IicI"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve, roc_auc_score\n",
        "from tabulate import tabulate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYY8BLiebWRs"
      },
      "source": [
        "def compute_all_metrics(data, silent=False):\n",
        "    def print_header(header):\n",
        "        print(header, \"-\" * (100 - len(header) - 1))\n",
        "    def print_prac(p, r, a, f):\n",
        "        print(\"Precision: {:.4f}; Recall: {:.4f}; Accuracy: {:.4f}; F1: {:.4f}\".format(p, r, a, f))\n",
        "    def print_footer():\n",
        "        print(\"-\" * 100, end=\"\\n\\n\")\n",
        "    def print_binary(header, p, r, a, f, report, confusion, roc_auc, t_counts, p_counts):\n",
        "        if not silent:\n",
        "            print_header(header)\n",
        "            print_prac(p, r, a, f)\n",
        "            \n",
        "            print(\"CLASSIFICATION REPORT:\")\n",
        "            print(report)\n",
        "            \n",
        "            print(\"CONFUSION MATRIX:\")\n",
        "            print(confusion)\n",
        "            \n",
        "            print(\"ROC AUC CURVE:\")\n",
        "            print(roc_auc)\n",
        "            \n",
        "            print(\"TRUE COUNTS\")\n",
        "            print(t_counts[0])\n",
        "            print(t_counts[1])\n",
        "            \n",
        "            print(\"PRED COUNTS\")\n",
        "            print(p_counts[0])\n",
        "            print(p_counts[1])\n",
        "            \n",
        "            print_footer()\n",
        "\n",
        "    def binary_scoring(y_true, y_pred, target_names):\n",
        "        p = precision_score(y_true, y_pred)\n",
        "        r = recall_score(y_true, y_pred)\n",
        "        a = accuracy_score(y_true, y_pred)\n",
        "        f = f1_score(y_true, y_pred)\n",
        "\n",
        "        if len(y_true.unique()) == 1 and len(y_pred.unique()) == 1:\n",
        "            target_names = [target_names[y_true.unique()[0]]]\n",
        "\n",
        "        report = classification_report(y_true, y_pred, target_names=target_names)\n",
        "        confusion = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "        roc_auc = roc_auc_score(y_true, y_pred) if len(y_true.unique()) > 1 else None\n",
        "\n",
        "        true_counts = y_true.value_counts(normalize=False), y_true.value_counts(normalize=True)\n",
        "        pred_counts = y_pred.value_counts(normalize=False), y_pred.value_counts(normalize=True)\n",
        "\n",
        "        return p, r, a, f, report, confusion, roc_auc, true_counts, pred_counts\n",
        "\n",
        "    sim_p, sim_r, sim_a, sim_f, sim_report, sim_conf, sim_roc, sim_tc, sim_pc = \\\n",
        "        binary_scoring(data.fake, data.su_pred_fake, [\"real\", \"fake\"])\n",
        "    \n",
        "    adv_p, adv_r, adv_a, adv_f, adv_report, adv_conf, adv_roc, adv_tc, adv_pc = \\\n",
        "        binary_scoring(data.fake, data.au_pred_fake, [\"real\", \"fake\"])\n",
        "    \n",
        "    print_binary(\"SIMPLE MODEL\",\n",
        "                 sim_p, sim_r, sim_a, sim_f, sim_report, sim_conf, sim_roc, sim_tc, sim_pc)\n",
        "    print_binary(\"ADVERSARIAL MODEL\",\n",
        "                 adv_p, adv_r, adv_a, adv_f, adv_report, adv_conf, adv_roc, adv_tc, adv_pc)\n",
        "\n",
        "    return {\n",
        "        \"simple_fake_real\": {\n",
        "            \"precision score\": sim_p,\n",
        "            \"recall score\": sim_r,\n",
        "            \"accuracy score\": sim_a, \n",
        "            \"f1 score\": sim_f,\n",
        "            \"classficiation report\": sim_report,\n",
        "            \"confusion matrix\": sim_conf,\n",
        "            \"roc auc\": sim_roc,\n",
        "            \"true counts\": sim_tc,\n",
        "            \"pred counts\": sim_pc\n",
        "        },\n",
        "        \"adversarial_fake_real\": {\n",
        "            \"precision score\": adv_p,\n",
        "            \"recall score\": adv_r,\n",
        "            \"accuracy score\": adv_a, \n",
        "            \"f1 score\": adv_f,\n",
        "            \"classficiation report\": adv_report,\n",
        "            \"confusion matrix\": adv_conf,\n",
        "            \"roc auc\": adv_roc,\n",
        "            \"true counts\": adv_tc,\n",
        "            \"pred counts\": adv_pc\n",
        "        }\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5roCMQ2VwXAi"
      },
      "source": [
        "def subclass_bias_scoring(data, bias_col, bias_value, silent=False):\n",
        "    def subset_scoring(y_true, y_pred):\n",
        "        p = precision_score(y_true, y_pred)\n",
        "        r = recall_score(y_true, y_pred)\n",
        "        a = accuracy_score(y_true, y_pred)\n",
        "        f = f1_score(y_true, y_pred)\n",
        "\n",
        "        roc_auc = roc_auc_score(y_true, y_pred) if len(y_true.unique()) > 1 else None\n",
        "\n",
        "        true_counts = y_true.value_counts(normalize=False), y_true.value_counts(normalize=True)\n",
        "        pred_counts = y_pred.value_counts(normalize=False), y_pred.value_counts(normalize=True)\n",
        "\n",
        "        tc_0 = true_counts[0][0] if 0 in true_counts[0] else 0\n",
        "        tc_1 = true_counts[0][1] if 1 in true_counts[0] else 0\n",
        "        pc_0 = pred_counts[0][0] if 0 in pred_counts[0] else 0\n",
        "        pc_1 = pred_counts[0][1] if 1 in pred_counts[0] else 0\n",
        "\n",
        "        ntc_0 = true_counts[1][0] if 0 in true_counts[1] else 0.0\n",
        "        ntc_1 = true_counts[1][1] if 1 in true_counts[1] else 0.0\n",
        "        npc_0 = pred_counts[1][0] if 0 in pred_counts[1] else 0.0\n",
        "        npc_1 = pred_counts[1][1] if 1 in pred_counts[1] else 0.0\n",
        "\n",
        "        return p, r, a, f, roc_auc, tc_0, tc_1, pc_0, pc_1, ntc_0, ntc_1, npc_0, npc_1\n",
        "\n",
        "    subclass_only = data[data[bias_col] == bias_value]\n",
        "    wout_subclass = data[data[bias_col] != bias_value]\n",
        "\n",
        "    metrics_sim_full = subset_scoring(data.fake,            data.su_pred_fake)\n",
        "    metrics_sim_only = subset_scoring(subclass_only.fake,   subclass_only.su_pred_fake)\n",
        "    metrics_sim_wout = subset_scoring(wout_subclass.fake,   wout_subclass.su_pred_fake)\n",
        "\n",
        "    metrics_adv_full = subset_scoring(data.fake,            data.au_pred_fake)\n",
        "    metrics_adv_only = subset_scoring(subclass_only.fake,   subclass_only.au_pred_fake)\n",
        "    metrics_adv_wout = subset_scoring(wout_subclass.fake,   wout_subclass.au_pred_fake)\n",
        "\n",
        "    if not silent:\n",
        "        print(\n",
        "            tabulate(\n",
        "            [\n",
        "                ['SIMPLE/FULL', *metrics_sim_full],\n",
        "                ['SIMPLE/ONLY', *metrics_sim_only],\n",
        "                ['SIMPLE/WOUT', *metrics_sim_wout],\n",
        "                ['ADVERS/FULL', *metrics_adv_full],\n",
        "                ['ADVERS/ONLY', *metrics_adv_only],\n",
        "                ['ADVERS/WOUT', *metrics_adv_wout]\n",
        "            ], \n",
        "            headers=[\n",
        "                        \"Model/Subset\", \"Precision\", \"Recall\", \"Accuracy\", \"F-1\", \n",
        "                        \"ROC AUC\",\n",
        "                        \"# TRUE REAL\", \"# TRUE FAKE\", \"# PRED REAL\", \"# PRED FAKE\",\n",
        "                        \"% TRUE REAL\", \"% TRUE FAKE\", \"% PRED REAL\", \"% PRED FAKE\"\n",
        "                    ]\n",
        "            )\n",
        "        )\n",
        "    return {\n",
        "        'SIMPLE/FULL': metrics_sim_full,\n",
        "        'SIMPLE/ONLY': metrics_sim_only,\n",
        "        'SIMPLE/WOUT': metrics_sim_wout,\n",
        "        'ADVERS/FULL': metrics_adv_full,\n",
        "        'ADVERS/ONLY': metrics_adv_only,\n",
        "        'ADVERS/WOUT': metrics_adv_wout\n",
        "    }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx8RSH76EK3W"
      },
      "source": [
        "colors = [\"#FF8C00\", \"#9932CC\"]\n",
        "\n",
        "def plot_simadv_comp(met_train, met_test, met_val, plot_metric, title, y_label, \n",
        "                     out_path,\n",
        "                     bar_width=0.25, colors=colors):\n",
        "    \n",
        "    sim_train_acc = met_train[\"simple_fake_real\"][plot_metric]\n",
        "    sim_test_acc = met_test[\"simple_fake_real\"][plot_metric]\n",
        "    sim_val_acc = met_val[\"simple_fake_real\"][plot_metric]\n",
        "\n",
        "    adv_train_acc = met_train[\"adversarial_fake_real\"][plot_metric]\n",
        "    adv_test_acc = met_test[\"adversarial_fake_real\"][plot_metric]\n",
        "    adv_val_acc = met_val[\"adversarial_fake_real\"][plot_metric]\n",
        "\n",
        "    heights_sim_bars = [sim_train_acc, sim_test_acc, sim_val_acc]\n",
        "    heights_adv_bars = [adv_train_acc, adv_test_acc, adv_val_acc]\n",
        "\n",
        "    sim_bar_pos = np.arange(len(heights_sim_bars))\n",
        "    adv_bar_pos = [x + bar_width for x in sim_bar_pos]\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    fig.patch.set_facecolor('white')\n",
        "\n",
        "    plt.xlabel('model', fontweight='bold')\n",
        "    plt.xticks([r + bar_width for r in range(len(heights_sim_bars))], ['train', 'test', 'valid.'])\n",
        "\n",
        "    plt.bar(sim_bar_pos, heights_sim_bars, color=colors[0], width=bar_width, edgecolor='white', label=\"simple\")\n",
        "    plt.bar(adv_bar_pos, heights_adv_bars, color=colors[1], width=bar_width, edgecolor='white', label=\"adversarial\")\n",
        "    \n",
        "    plt.ylabel(y_label, fontweight='bold')\n",
        "\n",
        "    plt.ylim([0.0, 1.1])\n",
        "    plt.yticks([0.0, 0.25, 0.5, 0.75, 1.0], [\"0.0\", \"0.25\", \"0.50\", \"0.75\", \"1.00\"])\n",
        "\n",
        "    plt.title(title)\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.savefig(out_path, bbox_inches='tight')\n",
        "    plt.show()"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOvjdXtegcR7"
      },
      "source": [
        "### Overall Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8eFNXPEbKzo",
        "outputId": "a95df59e-3c62-46d9-b45f-cf4cdbebf481"
      },
      "source": [
        "train_metrics_scores = compute_all_metrics(unbal_data_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SIMPLE MODEL ---------------------------------------------------------------------------------------\n",
            "Precision: 0.9343; Recall: 0.8827; Accuracy: 0.8909; F1: 0.9078\n",
            "CLASSIFICATION REPORT:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        real       0.83      0.90      0.87      4703\n",
            "        fake       0.93      0.88      0.91      7297\n",
            "\n",
            "    accuracy                           0.89     12000\n",
            "   macro avg       0.88      0.89      0.89     12000\n",
            "weighted avg       0.89      0.89      0.89     12000\n",
            "\n",
            "CONFUSION MATRIX:\n",
            "[[4250  453]\n",
            " [ 856 6441]]\n",
            "ROC AUC CURVE:\n",
            "0.8931850100724724\n",
            "TRUE COUNTS\n",
            "1    7297\n",
            "0    4703\n",
            "Name: fake, dtype: int64\n",
            "1    0.608083\n",
            "0    0.391917\n",
            "Name: fake, dtype: float64\n",
            "PRED COUNTS\n",
            "1.0    6894\n",
            "0.0    5106\n",
            "Name: su_pred_fake, dtype: int64\n",
            "1.0    0.5745\n",
            "0.0    0.4255\n",
            "Name: su_pred_fake, dtype: float64\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "ADVERSARIAL MODEL ----------------------------------------------------------------------------------\n",
            "Precision: 0.9335; Recall: 0.9178; Accuracy: 0.9103; F1: 0.9256\n",
            "CLASSIFICATION REPORT:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        real       0.88      0.90      0.89      4703\n",
            "        fake       0.93      0.92      0.93      7297\n",
            "\n",
            "    accuracy                           0.91     12000\n",
            "   macro avg       0.90      0.91      0.91     12000\n",
            "weighted avg       0.91      0.91      0.91     12000\n",
            "\n",
            "CONFUSION MATRIX:\n",
            "[[4226  477]\n",
            " [ 600 6697]]\n",
            "ROC AUC CURVE:\n",
            "0.9081749026328647\n",
            "TRUE COUNTS\n",
            "1    7297\n",
            "0    4703\n",
            "Name: fake, dtype: int64\n",
            "1    0.608083\n",
            "0    0.391917\n",
            "Name: fake, dtype: float64\n",
            "PRED COUNTS\n",
            "1.0    7174\n",
            "0.0    4826\n",
            "Name: au_pred_fake, dtype: int64\n",
            "1.0    0.597833\n",
            "0.0    0.402167\n",
            "Name: au_pred_fake, dtype: float64\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwoVaywWbUJb",
        "outputId": "aa66d578-8546-4ce0-e94b-bec11eb2639e"
      },
      "source": [
        "test_metrics_scores = compute_all_metrics(unbal_data_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SIMPLE MODEL ---------------------------------------------------------------------------------------\n",
            "Precision: 0.9217; Recall: 0.8620; Accuracy: 0.8723; F1: 0.8908\n",
            "CLASSIFICATION REPORT:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        real       0.81      0.89      0.85      1545\n",
            "        fake       0.92      0.86      0.89      2362\n",
            "\n",
            "    accuracy                           0.87      3907\n",
            "   macro avg       0.86      0.88      0.87      3907\n",
            "weighted avg       0.88      0.87      0.87      3907\n",
            "\n",
            "CONFUSION MATRIX:\n",
            "[[1372  173]\n",
            " [ 326 2036]]\n",
            "ROC AUC CURVE:\n",
            "0.8750036308432599\n",
            "TRUE COUNTS\n",
            "1    2362\n",
            "0    1545\n",
            "Name: fake, dtype: int64\n",
            "1    0.604556\n",
            "0    0.395444\n",
            "Name: fake, dtype: float64\n",
            "PRED COUNTS\n",
            "1.0    2209\n",
            "0.0    1698\n",
            "Name: su_pred_fake, dtype: int64\n",
            "1.0    0.565395\n",
            "0.0    0.434605\n",
            "Name: su_pred_fake, dtype: float64\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "ADVERSARIAL MODEL ----------------------------------------------------------------------------------\n",
            "Precision: 0.9196; Recall: 0.9001; Accuracy: 0.8920; F1: 0.9097\n",
            "CLASSIFICATION REPORT:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        real       0.85      0.88      0.87      1545\n",
            "        fake       0.92      0.90      0.91      2362\n",
            "\n",
            "    accuracy                           0.89      3907\n",
            "   macro avg       0.89      0.89      0.89      3907\n",
            "weighted avg       0.89      0.89      0.89      3907\n",
            "\n",
            "CONFUSION MATRIX:\n",
            "[[1359  186]\n",
            " [ 236 2126]]\n",
            "ROC AUC CURVE:\n",
            "0.8898481622452586\n",
            "TRUE COUNTS\n",
            "1    2362\n",
            "0    1545\n",
            "Name: fake, dtype: int64\n",
            "1    0.604556\n",
            "0    0.395444\n",
            "Name: fake, dtype: float64\n",
            "PRED COUNTS\n",
            "1.0    2312\n",
            "0.0    1595\n",
            "Name: au_pred_fake, dtype: int64\n",
            "1.0    0.591758\n",
            "0.0    0.408242\n",
            "Name: au_pred_fake, dtype: float64\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqcmKv40gOFU",
        "outputId": "21fc7bb3-3b59-495f-acc8-2e7a96294e83"
      },
      "source": [
        "val_metrics_scores = compute_all_metrics(unbal_data_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SIMPLE MODEL ---------------------------------------------------------------------------------------\n",
            "Precision: 0.9294; Recall: 0.8782; Accuracy: 0.8842; F1: 0.9031\n",
            "CLASSIFICATION REPORT:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        real       0.82      0.89      0.86      1356\n",
            "        fake       0.93      0.88      0.90      2160\n",
            "\n",
            "    accuracy                           0.88      3516\n",
            "   macro avg       0.88      0.89      0.88      3516\n",
            "weighted avg       0.89      0.88      0.89      3516\n",
            "\n",
            "CONFUSION MATRIX:\n",
            "[[1212  144]\n",
            " [ 263 1897]]\n",
            "ROC AUC CURVE:\n",
            "0.886023025237627\n",
            "TRUE COUNTS\n",
            "1    2160\n",
            "0    1356\n",
            "Name: fake, dtype: int64\n",
            "1    0.614334\n",
            "0    0.385666\n",
            "Name: fake, dtype: float64\n",
            "PRED COUNTS\n",
            "1.0    2041\n",
            "0.0    1475\n",
            "Name: su_pred_fake, dtype: int64\n",
            "1.0    0.580489\n",
            "0.0    0.419511\n",
            "Name: su_pred_fake, dtype: float64\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "ADVERSARIAL MODEL ----------------------------------------------------------------------------------\n",
            "Precision: 0.9185; Recall: 0.9023; Accuracy: 0.8908; F1: 0.9103\n",
            "CLASSIFICATION REPORT:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        real       0.85      0.87      0.86      1356\n",
            "        fake       0.92      0.90      0.91      2160\n",
            "\n",
            "    accuracy                           0.89      3516\n",
            "   macro avg       0.88      0.89      0.89      3516\n",
            "weighted avg       0.89      0.89      0.89      3516\n",
            "\n",
            "CONFUSION MATRIX:\n",
            "[[1183  173]\n",
            " [ 211 1949]]\n",
            "ROC AUC CURVE:\n",
            "0.887366846935431\n",
            "TRUE COUNTS\n",
            "1    2160\n",
            "0    1356\n",
            "Name: fake, dtype: int64\n",
            "1    0.614334\n",
            "0    0.385666\n",
            "Name: fake, dtype: float64\n",
            "PRED COUNTS\n",
            "1.0    2122\n",
            "0.0    1394\n",
            "Name: au_pred_fake, dtype: int64\n",
            "1.0    0.603527\n",
            "0.0    0.396473\n",
            "Name: au_pred_fake, dtype: float64\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "JUQt5APORVrz",
        "outputId": "1d728bdc-e7d9-42c6-cfe7-af613f9e836a"
      },
      "source": [
        "plot_metric = \"accuracy score\"\n",
        "plot_simadv_comp(\n",
        "    train_metrics_scores, test_metrics_scores, val_metrics_scores, \n",
        "    plot_metric, \n",
        "    \"Accuracy Score Comparison\", \"accuracy\",\n",
        "    destination_folder + \"accuracy_comp.png\"\n",
        ")"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "GBEhbjGKVRqo",
        "outputId": "340a358d-f4db-4d6c-a6e5-a879a1baae2d"
      },
      "source": [
        "plot_metric = \"roc auc\"\n",
        "plot_simadv_comp(\n",
        "    train_metrics_scores, test_metrics_scores, val_metrics_scores,\n",
        "    plot_metric, \n",
        "    \"ROC AUC Score Comparison\", \"roc auc\",\n",
        "    destination_folder + \"rocauc_comp.png\"\n",
        ")"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "HdKxCy9MVva0",
        "outputId": "c46954f2-7a0e-4be5-dcdb-102ae496b4b6"
      },
      "source": [
        "plot_metric = \"f1 score\"\n",
        "plot_simadv_comp(\n",
        "    train_metrics_scores, test_metrics_scores, val_metrics_scores,\n",
        "    plot_metric, \n",
        "    \"F1 Score Comparison\", \"f1 score\",\n",
        "    destination_folder + \"f1_comp.png\"\n",
        ")"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JZlVlxS4wti"
      },
      "source": [
        "### Subclass Bias Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrBUHRKh3uJd",
        "outputId": "12b8ba4f-ed16-40d6-a174-1e3a8d4f6015"
      },
      "source": [
        "comparing_keyword_climate = subclass_bias_scoring(unbal_data_test, \"keyword\", \"climate change\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model/Subset      Precision    Recall    Accuracy       F-1    ROC AUC    # TRUE REAL    # TRUE FAKE    # PRED REAL    # PRED FAKE    % TRUE REAL    % TRUE FAKE    % PRED REAL    % PRED FAKE\n",
            "--------------  -----------  --------  ----------  --------  ---------  -------------  -------------  -------------  -------------  -------------  -------------  -------------  -------------\n",
            "SIMPLE/FULL        0.921684  0.861981    0.872281  0.890834   0.875004           1545           2362           1698           2209       0.395444       0.604556       0.434605       0.565395\n",
            "SIMPLE/ONLY        0.830189  0.830189    0.890244  0.830189   0.874554            111             53            111             53       0.676829       0.323171       0.676829       0.323171\n",
            "SIMPLE/WOUT        0.923933  0.862711    0.871493  0.892273   0.874173           1434           2309           1587           2156       0.383115       0.616885       0.423991       0.576009\n",
            "ADVERS/FULL        0.91955   0.900085    0.891989  0.909713   0.889848           1545           2362           1595           2312       0.395444       0.604556       0.408242       0.591758\n",
            "ADVERS/ONLY        0.867925  0.867925    0.914634  0.867925   0.902431            111             53            111             53       0.676829       0.323171       0.676829       0.323171\n",
            "ADVERS/WOUT        0.920761  0.900823    0.890997  0.910683   0.887999           1434           2309           1484           2259       0.383115       0.616885       0.396473       0.603527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Veyy7OF84HMJ",
        "outputId": "29b827a8-69ab-428b-fdf8-a33939d0cd6b"
      },
      "source": [
        "comparing_keyword_business = subclass_bias_scoring(unbal_data_test, \"keyword\", \"business\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model/Subset      Precision    Recall    Accuracy       F-1    ROC AUC    # TRUE REAL    # TRUE FAKE    # PRED REAL    # PRED FAKE    % TRUE REAL    % TRUE FAKE    % PRED REAL    % PRED FAKE\n",
            "--------------  -----------  --------  ----------  --------  ---------  -------------  -------------  -------------  -------------  -------------  -------------  -------------  -------------\n",
            "SIMPLE/FULL        0.921684  0.861981    0.872281  0.890834   0.875004           1545           2362           1698           2209       0.395444       0.604556       0.434605       0.565395\n",
            "SIMPLE/ONLY        0.9375    0.79646     0.829412  0.861244   0.845599             57            113             74             96       0.335294       0.664706       0.435294       0.564706\n",
            "SIMPLE/WOUT        0.920965  0.865273    0.874231  0.892251   0.876521           1488           2249           1624           2113       0.39818        0.60182        0.434573       0.565427\n",
            "ADVERS/FULL        0.91955   0.900085    0.891989  0.909713   0.889848           1545           2362           1595           2312       0.395444       0.604556       0.408242       0.591758\n",
            "ADVERS/ONLY        0.961905  0.893805    0.905882  0.926606   0.911815             57            113             65            105       0.335294       0.664706       0.382353       0.617647\n",
            "ADVERS/WOUT        0.917535  0.9004      0.891357  0.908887   0.889044           1488           2249           1530           2207       0.39818        0.60182        0.409419       0.590581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry_HwRFn5AhC",
        "outputId": "f9dc6d64-3a95-4b40-fdab-bff64eb73110"
      },
      "source": [
        "comparing_keyword_politics = subclass_bias_scoring(unbal_data_test, \"keyword\", \"politics\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model/Subset      Precision    Recall    Accuracy       F-1    ROC AUC    # TRUE REAL    # TRUE FAKE    # PRED REAL    # PRED FAKE    % TRUE REAL    % TRUE FAKE    % PRED REAL    % PRED FAKE\n",
            "--------------  -----------  --------  ----------  --------  ---------  -------------  -------------  -------------  -------------  -------------  -------------  -------------  -------------\n",
            "SIMPLE/FULL        0.921684  0.861981    0.872281  0.890834   0.875004           1545           2362           1698           2209       0.395444       0.604556       0.434605       0.565395\n",
            "SIMPLE/ONLY        0.905292  0.668724    0.834325  0.769231   0.80976             691            486            818            359       0.587086       0.412914       0.694987       0.305013\n",
            "SIMPLE/WOUT        0.924865  0.912047    0.888645  0.918411   0.874642            854           1876            880           1850       0.312821       0.687179       0.322344       0.677656\n",
            "ADVERS/FULL        0.91955   0.900085    0.891989  0.909713   0.889848           1545           2362           1595           2312       0.395444       0.604556       0.408242       0.591758\n",
            "ADVERS/ONLY        0.864929  0.751029    0.848768  0.803965   0.83427             691            486            755            422       0.587086       0.412914       0.641461       0.358539\n",
            "ADVERS/WOUT        0.931746  0.938699    0.910623  0.93521    0.893823            854           1876            840           1890       0.312821       0.687179       0.307692       0.692308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUJP99K85HQy",
        "outputId": "58ad384f-73be-4069-8354-939e35def6a7"
      },
      "source": [
        "comparing_keyword_science = subclass_bias_scoring(unbal_data_test, \"keyword\", \"science\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model/Subset      Precision    Recall    Accuracy       F-1    ROC AUC    # TRUE REAL    # TRUE FAKE    # PRED REAL    # PRED FAKE    % TRUE REAL    % TRUE FAKE    % PRED REAL    % PRED FAKE\n",
            "--------------  -----------  --------  ----------  --------  ---------  -------------  -------------  -------------  -------------  -------------  -------------  -------------  -------------\n",
            "SIMPLE/FULL        0.921684  0.861981    0.872281  0.890834   0.875004           1545           2362           1698           2209       0.395444       0.604556       0.434605       0.565395\n",
            "SIMPLE/ONLY        0.966102  0.897638    0.885906  0.930612   0.85791              22            127             31            118       0.147651       0.852349       0.208054       0.791946\n",
            "SIMPLE/WOUT        0.919177  0.859955    0.87174   0.888581   0.874495           1523           2235           1667           2091       0.405269       0.594731       0.443587       0.556413\n",
            "ADVERS/FULL        0.91955   0.900085    0.891989  0.909713   0.889848           1545           2362           1595           2312       0.395444       0.604556       0.408242       0.591758\n",
            "ADVERS/ONLY        0.944     0.929134    0.892617  0.936508   0.805476             22            127             24            125       0.147651       0.852349       0.161074       0.838926\n",
            "ADVERS/WOUT        0.918153  0.898434    0.891964  0.908186   0.890451           1523           2235           1571           2187       0.405269       0.594731       0.418042       0.581958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRVY9WDv5VU6",
        "outputId": "391a6226-71c7-477e-9984-e4655818c811"
      },
      "source": [
        "comparing_keyword_china = subclass_bias_scoring(unbal_data_test, \"keyword\", \"china\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model/Subset      Precision    Recall    Accuracy       F-1    ROC AUC    # TRUE REAL    # TRUE FAKE    # PRED REAL    # PRED FAKE    % TRUE REAL    % TRUE FAKE    % PRED REAL    % PRED FAKE\n",
            "--------------  -----------  --------  ----------  --------  ---------  -------------  -------------  -------------  -------------  -------------  -------------  -------------  -------------\n",
            "SIMPLE/FULL        0.921684  0.861981    0.872281  0.890834   0.875004           1545           2362           1698           2209       0.395444       0.604556       0.434605       0.565395\n",
            "SIMPLE/ONLY        0.911504  0.876596    0.853731  0.893709   0.838298            100            235            109            226       0.298507       0.701493       0.325373       0.674627\n",
            "SIMPLE/WOUT        0.922844  0.860367    0.87402   0.890511   0.877242           1445           2127           1589           1983       0.404535       0.595465       0.444849       0.555151\n",
            "ADVERS/FULL        0.91955   0.900085    0.891989  0.909713   0.889848           1545           2362           1595           2312       0.395444       0.604556       0.408242       0.591758\n",
            "ADVERS/ONLY        0.886179  0.92766     0.865672  0.906445   0.82383             100            235             89            246       0.298507       0.701493       0.265672       0.734328\n",
            "ADVERS/WOUT        0.923524  0.897038    0.894457  0.910088   0.893848           1445           2127           1506           2066       0.404535       0.595465       0.421613       0.578387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fxIRaqS5Ue8",
        "outputId": "d6879810-8fb5-4840-a8ba-6f3f4e551ffb"
      },
      "source": [
        "comparing_keyword_trump = subclass_bias_scoring(unbal_data_test, \"has_mk_donald trump\", 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model/Subset      Precision    Recall    Accuracy       F-1    ROC AUC    # TRUE REAL    # TRUE FAKE    # PRED REAL    # PRED FAKE    % TRUE REAL    % TRUE FAKE    % PRED REAL    % PRED FAKE\n",
            "--------------  -----------  --------  ----------  --------  ---------  -------------  -------------  -------------  -------------  -------------  -------------  -------------  -------------\n",
            "SIMPLE/FULL        0.921684  0.861981    0.872281  0.890834   0.875004           1545           2362           1698           2209       0.395444       0.604556       0.434605       0.565395\n",
            "SIMPLE/ONLY        0.896104  0.657143    0.903297  0.758242   0.817143            350            105            378             77       0.769231       0.230769       0.830769       0.169231\n",
            "SIMPLE/WOUT        0.922608  0.871511    0.868192  0.896332   0.866718           1195           2257           1320           2132       0.346176       0.653824       0.382387       0.617613\n",
            "ADVERS/FULL        0.91955   0.900085    0.891989  0.909713   0.889848           1545           2362           1595           2312       0.395444       0.604556       0.408242       0.591758\n",
            "ADVERS/ONLY        0.833333  0.761905    0.90989   0.79602    0.858095            350            105            359             96       0.769231       0.230769       0.789011       0.210989\n",
            "ADVERS/WOUT        0.923285  0.906513    0.889629  0.914822   0.882127           1195           2257           1236           2216       0.346176       0.653824       0.358053       0.641947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMMnn4s65XEh",
        "outputId": "f10b6ea5-2f7e-48f0-d751-96761c0a5850"
      },
      "source": [
        "comparing_keyword_obama = subclass_bias_scoring(unbal_data_test, \"has_mk_barack obama\", 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model/Subset      Precision    Recall    Accuracy       F-1    ROC AUC    # TRUE REAL    # TRUE FAKE    # PRED REAL    # PRED FAKE    % TRUE REAL    % TRUE FAKE    % PRED REAL    % PRED FAKE\n",
            "--------------  -----------  --------  ----------  --------  ---------  -------------  -------------  -------------  -------------  -------------  -------------  -------------  -------------\n",
            "SIMPLE/FULL        0.921684  0.861981    0.872281  0.890834   0.875004           1545           2362           1698           2209       0.395444       0.604556       0.434605       0.565395\n",
            "SIMPLE/ONLY        0.9       0.459184    0.805369  0.608108   0.717092            200             98            248             50       0.671141       0.328859       0.832215       0.167785\n",
            "SIMPLE/WOUT        0.922186  0.879417    0.877805  0.900294   0.877255           1345           2264           1450           2159       0.372679       0.627321       0.401773       0.598227\n",
            "ADVERS/FULL        0.91955   0.900085    0.891989  0.909713   0.889848           1545           2362           1595           2312       0.395444       0.604556       0.408242       0.591758\n",
            "ADVERS/ONLY        0.869565  0.612245    0.842282  0.718563   0.783622            200             98            229             69       0.671141       0.328859       0.768456       0.231544\n",
            "ADVERS/WOUT        0.921088  0.912544    0.896093  0.916796   0.890473           1345           2264           1366           2243       0.372679       0.627321       0.378498       0.621502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0D7IobJ5o6O",
        "outputId": "9848458c-19e5-4caa-fa57-a2b8f61514ff"
      },
      "source": [
        "comparing_tag_russia = subclass_bias_scoring(unbal_data_test, \"has_mk_russia\", 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model/Subset      Precision    Recall    Accuracy       F-1    ROC AUC    # TRUE REAL    # TRUE FAKE    # PRED REAL    # PRED FAKE    % TRUE REAL    % TRUE FAKE    % PRED REAL    % PRED FAKE\n",
            "--------------  -----------  --------  ----------  --------  ---------  -------------  -------------  -------------  -------------  -------------  -------------  -------------  -------------\n",
            "SIMPLE/FULL        0.921684  0.861981    0.872281  0.890834   0.875004           1545           2362           1698           2209       0.395444       0.604556       0.434605       0.565395\n",
            "SIMPLE/ONLY        0.959813  0.975309    0.946759  0.967499   0.899177            243           1053            226           1070       0.1875         0.8125         0.174383       0.825617\n",
            "SIMPLE/WOUT        0.885865  0.770817    0.835312  0.824346   0.835486           1302           1309           1472           1139       0.49866        0.50134        0.563769       0.436231\n",
            "ADVERS/FULL        0.91955   0.900085    0.891989  0.909713   0.889848           1545           2362           1595           2312       0.395444       0.604556       0.408242       0.591758\n",
            "ADVERS/ONLY        0.965583  0.959164    0.939043  0.962363   0.905508            243           1053            250           1046       0.1875         0.8125         0.192901       0.807099\n",
            "ADVERS/WOUT        0.881517  0.852559    0.868633  0.866796   0.868676           1302           1309           1345           1266       0.49866        0.50134        0.515128       0.484872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJX-c72d6Zlk",
        "outputId": "58df281c-73a3-4646-9ba2-6d4053779373"
      },
      "source": [
        "comparing_tag_israel = subclass_bias_scoring(unbal_data_test, \"has_mk_israel\", 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model/Subset      Precision    Recall    Accuracy       F-1    ROC AUC    # TRUE REAL    # TRUE FAKE    # PRED REAL    # PRED FAKE    % TRUE REAL    % TRUE FAKE    % PRED REAL    % PRED FAKE\n",
            "--------------  -----------  --------  ----------  --------  ---------  -------------  -------------  -------------  -------------  -------------  -------------  -------------  -------------\n",
            "SIMPLE/FULL        0.921684  0.861981    0.872281  0.890834   0.875004           1545           2362           1698           2209       0.395444       0.604556       0.434605       0.565395\n",
            "SIMPLE/ONLY        0.9       0.75        0.849057  0.818182   0.840517             29             24             33             20       0.54717        0.45283        0.622642       0.377358\n",
            "SIMPLE/WOUT        0.921882  0.863131    0.8726    0.89154    0.875167           1516           2338           1665           2189       0.393358       0.606642       0.432019       0.567981\n",
            "ADVERS/FULL        0.91955   0.900085    0.891989  0.909713   0.889848           1545           2362           1595           2312       0.395444       0.604556       0.408242       0.591758\n",
            "ADVERS/ONLY        0.952381  0.833333    0.90566   0.888889   0.899425             29             24             32             21       0.54717        0.45283        0.603774       0.396226\n",
            "ADVERS/WOUT        0.919249  0.90077     0.891801  0.909916   0.889369           1516           2338           1563           2291       0.393358       0.606642       0.405553       0.594447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddFXpbRj6d4F",
        "outputId": "59839611-3e36-4fcb-a283-9c06d36695bb"
      },
      "source": [
        "comparing_tag_trump = subclass_bias_scoring(unbal_data_test, \"has_mk_donald trump\", 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model/Subset      Precision    Recall    Accuracy       F-1    ROC AUC    # TRUE REAL    # TRUE FAKE    # PRED REAL    # PRED FAKE    % TRUE REAL    % TRUE FAKE    % PRED REAL    % PRED FAKE\n",
            "--------------  -----------  --------  ----------  --------  ---------  -------------  -------------  -------------  -------------  -------------  -------------  -------------  -------------\n",
            "SIMPLE/FULL        0.921684  0.861981    0.872281  0.890834   0.875004           1545           2362           1698           2209       0.395444       0.604556       0.434605       0.565395\n",
            "SIMPLE/ONLY        0.896104  0.657143    0.903297  0.758242   0.817143            350            105            378             77       0.769231       0.230769       0.830769       0.169231\n",
            "SIMPLE/WOUT        0.922608  0.871511    0.868192  0.896332   0.866718           1195           2257           1320           2132       0.346176       0.653824       0.382387       0.617613\n",
            "ADVERS/FULL        0.91955   0.900085    0.891989  0.909713   0.889848           1545           2362           1595           2312       0.395444       0.604556       0.408242       0.591758\n",
            "ADVERS/ONLY        0.833333  0.761905    0.90989   0.79602    0.858095            350            105            359             96       0.769231       0.230769       0.789011       0.210989\n",
            "ADVERS/WOUT        0.923285  0.906513    0.889629  0.914822   0.882127           1195           2257           1236           2216       0.346176       0.653824       0.358053       0.641947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--eij1bL6eh0",
        "outputId": "333b9c3e-c8e4-42aa-8054-73315513b681"
      },
      "source": [
        "comparing_tag_hillary = subclass_bias_scoring(unbal_data_test, \"has_mk_hillary clinton\", 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model/Subset      Precision    Recall    Accuracy       F-1    ROC AUC    # TRUE REAL    # TRUE FAKE    # PRED REAL    # PRED FAKE    % TRUE REAL    % TRUE FAKE    % PRED REAL    % PRED FAKE\n",
            "--------------  -----------  --------  ----------  --------  ---------  -------------  -------------  -------------  -------------  -------------  -------------  -------------  -------------\n",
            "SIMPLE/FULL        0.921684  0.861981    0.872281  0.890834   0.875004           1545           2362           1698           2209       0.395444       0.604556       0.434605       0.565395\n",
            "SIMPLE/ONLY        0.871795  0.419753    0.692308  0.566667   0.681467             88             81            130             39       0.52071        0.47929        0.769231       0.230769\n",
            "SIMPLE/WOUT        0.922581  0.877685    0.880417  0.899573   0.88119            1457           2281           1568           2170       0.389781       0.610219       0.419476       0.580524\n",
            "ADVERS/FULL        0.91955   0.900085    0.891989  0.909713   0.889848           1545           2362           1595           2312       0.395444       0.604556       0.408242       0.591758\n",
            "ADVERS/ONLY        0.921569  0.580247    0.775148  0.712121   0.767396             88             81            118             51       0.52071        0.47929        0.698225       0.301775\n",
            "ADVERS/WOUT        0.919505  0.911442    0.897271  0.915456   0.893264           1457           2281           1477           2261       0.389781       0.610219       0.395131       0.604869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1xLY5bpAKHO"
      },
      "source": [
        "NOTE: comparisons on authors could be made, but all samples with author data happened to be labelled real, so comparision does not give much information for bias for/against that author. Plus, authors are directly related to the source domain, which is directly related to the label for the sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXlSuk_GAlHh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}